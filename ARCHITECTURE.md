# Architecture Technique - DamageControl AI

## ðŸ— Vue Globale

L'application suit une architecture client-serveur avec traitement IA cÃ´tÃ© backend.

```mermaid
graph TD
    User[Utilisateur] -->|Upload Image| Frontend[Frontend Vue.js]
    Frontend -->|HTTP POST| Backend[Backend FastAPI]
    Backend -->|Stockage Local| Files[SystÃ¨me de Fichiers]
    Backend -->|InfÃ©rence| AI[Depth Anything Model]
    AI -->|Depth Map| Backend
    Backend -->|RÃ©sultats| Frontend
    Frontend -->|Affichage| User
```

## ðŸ”§ Choix Technologiques & Justification

### 1. Frontend : Vue.js 3 + TailwindCSS

**Pourquoi Vue.js ?**

- ExpÃ©rience prÃ©alable avec Vue.js
- Ã‰cosystÃ¨me riche et moderne (Vite, Composition API)
- Excellente rÃ©activitÃ© pour les interfaces dynamiques

**TailwindCSS :**

- Design rapide et moderne
- Utility-first pour un contrÃ´le total
- Dark mode natif

**TresJS (âœ… ImplÃ©mentÃ©) :**

- Ã‰quivalent de React-Three-Fiber pour Vue
- Visualisation 3D interactive des depth maps
- OrbitControls pour rotation/zoom/pan
- Displacement mapping pour relief 3D

### 2. Backend : Python FastAPI

**Pourquoi FastAPI ?**

- Standard de l'industrie pour servir des modÃ¨les IA
- Performance Ã©levÃ©e (asynchrone)
- Documentation automatique (Swagger UI)
- Validation de donnÃ©es avec Pydantic

**Traitement d'images :**

- **OpenCV** : Normalisation et colormap des depth maps
- **PIL/Pillow** : Manipulation d'images
- **NumPy** : Calculs matriciels

### 3. Intelligence Artificielle (Hugging Face + Ultralytics)

**ModÃ¨les utilisÃ©s :**

#### Depth Anything (âœ… ImplÃ©mentÃ©)

- **ModÃ¨le** : `LiheYoung/depth-anything-small-hf`
- **TÃ¢che** : Estimation de profondeur monoculaire
- **Usage** : GÃ©nÃ¨re une carte de profondeur 3D Ã  partir d'une image 2D
- **Performance** : ~2-5 secondes par image (CPU)
- **Visualisation** : Colormap INFERNO (rouge = proche, bleu = loin)

#### YOLOv8 (âœ… ImplÃ©mentÃ©)

- **ModÃ¨le** : `yolov8n.pt` (nano)
- **TÃ¢che** : DÃ©tection d'objets gÃ©nÃ©riques
- **Usage** : Identifier les objets dans l'image (voitures, personnes, camions)
- **Performance** : ~1-2 secondes par image (CPU)
- **Threshold** : 25% de confiance minimum

#### OWL-ViT (âœ… ImplÃ©mentÃ©)

- **ModÃ¨le** : `google/owlvit-base-patch32`
- **TÃ¢che** : Zero-Shot Object Detection
- **Usage** : DÃ©tecter des piÃ¨ces spÃ©cifiques via requÃªtes textuelles (bumper, door, wheel, etc.)
- **Performance** : ~5-10 secondes par image (CPU)
- **Threshold** : 5% de confiance minimum
- **Avantage** : Pas besoin d'entraÃ®nement pour de nouvelles classes

#### Analyse de Contrats (âœ… ImplÃ©mentÃ© - Alternative Ã  TAPAS)

- **Approche** : PyPDF2 + Tesseract OCR + Regex
- **TÃ¢che** : Extraction de texte et analyse de contrats
- **Usage** : Extraire franchises, plafonds et garanties depuis des contrats PDF/Images
- **Performance** : ~2-5 secondes par document
- **Avantage** : Plus simple et plus rapide que TAPAS pour ce cas d'usage

### 4. Stockage : SystÃ¨me de Fichiers Local

**Pourquoi pas MinIO/S3 pour le MVP ?**

- SimplicitÃ© de dÃ©veloppement
- Pas de dÃ©pendance Docker
- Suffisant pour la preuve de concept

**Structure actuelle :**

```
/backend/uploads/
â”œâ”€â”€ [uuid].jpg                  # Image originale
â”œâ”€â”€ depth_[uuid].jpg            # Depth map gÃ©nÃ©rÃ©e
â”œâ”€â”€ detected_[uuid].jpg         # YOLO annotations
â”œâ”€â”€ parts_[uuid].jpg            # OWL-ViT annotations
â””â”€â”€ /contracts/
    â””â”€â”€ [uuid].pdf              # Contrats uploadÃ©s
```

**Migration future :**

- Facile Ã  migrer vers S3/MinIO en production
- Changement minimal du code (juste la configuration)

## ðŸ“Š Flux de DonnÃ©es

### 1. Upload d'Image

```
User â†’ Frontend â†’ POST /upload â†’ Backend â†’ Filesystem
                                         â†“
                                    Response (filename, url)
```

### 2. Analyse de Profondeur

```
User â†’ Frontend â†’ POST /analyze/{filename} â†’ Backend
                                              â†“
                                         Load Image
                                              â†“
                                    Depth Anything Model
                                              â†“
                                    Generate Depth Map
                                              â†“
                                    Apply Colormap (OpenCV)
                                              â†“
                                    Save to Filesystem
                                              â†“
                                    Response (depth_map_url, stats)
                                              â†“
                                         Frontend
                                              â†“
                                    Display Side-by-Side
```

### 3. DÃ©tection d'Objets (YOLO + OWL-ViT)

```
User â†’ Frontend â†’ POST /detect/objects/{filename} â†’ Backend
                                                      â†“
                                                 Load Image
                                                      â†“
                                                 YOLOv8 Model
                                                      â†“
                                                 Detect Objects
                                                      â†“
                                                 Draw Bounding Boxes
                                                      â†“
                                                 Save Annotated Image
                                                      â†“
                                                 Response (detections, url)

User â†’ Frontend â†’ POST /detect/parts/{filename} â†’ Backend
                                                    â†“
                                               Load Image
                                                    â†“
                                               OWL-ViT Model
                                                    â†“
                                               Zero-Shot Detection
                                                    â†“
                                               Draw Bounding Boxes
                                                    â†“
                                               Save Annotated Image
                                                    â†“
                                               Response (parts, url)
```

### 4. Analyse de Contrat

```
User â†’ Frontend â†’ POST /upload/contract â†’ Backend
                                            â†“
                                       Save PDF/Image
                                            â†“
                                       Response (filename)
                                            â†“
User â†’ Frontend â†’ POST /analyze/contract/{filename} â†’ Backend
                                                        â†“
                                                   Load Document
                                                        â†“
                                                   Extract Text
                                                   (PyPDF2 + Tesseract)
                                                        â†“
                                                   Regex Analysis
                                                        â†“
                                                   Extract Guarantees
                                                        â†“
                                                   Response (franchise, plafond, garanties)
```

### 5. Ã‰valuation de Sinistre (Logique MÃ©tier)

```
User â†’ Frontend â†’ POST /evaluate/claim â†’ Backend
                                           â†“
                                      ClaimEvaluator
                                           â†“
                                      Load Image
                                           â†“
                                      Zero-Shot Detection (parts)
                                           â†“
                                      Load Contract
                                           â†“
                                      Extract Contract Data
                                           â†“
                                      Calculate Estimated Cost
                                           â†“
                                      Check Coverage
                                           â†“
                                      Calculate Reimbursement
                                           â†“
                                      Response (decision, cost, reimbursement, damages)
```

## ðŸ”’ SÃ©curitÃ© & Limitations

### SÃ©curitÃ© actuelle :

- Validation du type de fichier (images uniquement)
- Noms de fichiers UUID (Ã©vite les collisions)
- CORS configurÃ© pour localhost uniquement

### Limitations MVP :

- Pas d'authentification utilisateur
- Stockage local (non scalable)
- CPU uniquement (pas de GPU)
- Pas de limite de taille de fichier

### AmÃ©liorations futures :

- Authentification JWT
- Stockage cloud (S3)
- Support GPU pour accÃ©lÃ©ration
- Rate limiting
- Compression d'images

## ðŸ“ˆ Performance

### Temps de traitement (CPU - Intel i7) :

- Upload : < 100ms
- Depth Estimation : 2-5 secondes
- Total (upload + analyse) : ~5 secondes

### Optimisations possibles :

- Utilisation GPU (CUDA) : 10x plus rapide
- ModÃ¨le quantifiÃ© : 2x plus rapide
- Batch processing : Traiter plusieurs images en parallÃ¨le

## ðŸš€ Ã‰volution de l'Architecture

### Phase actuelle (MVP) :

- Monolithe simple
- Stockage local
- CPU uniquement

### Phase 2 (Production) :

- SÃ©paration Frontend/Backend (dÃ©ploiement indÃ©pendant)
- Stockage S3
- GPU pour l'infÃ©rence
- Cache Redis pour les rÃ©sultats

### Infrastructure Actuelle (Production) :

**Frontend** :

- Plateforme : Netlify
- Build : Vite (Vue.js 3)
- CDN : Global (Netlify Edge)
- DÃ©ploiement : Automatique via GitHub

**Backend** :

- Plateforme : Hugging Face Spaces
- Runtime : Docker (Python 3.9)
- RAM : 16 GB
- ModÃ¨les IA : Depth Anything, YOLOv8, OWL-ViT
- API : FastAPI avec documentation Swagger

**Avantages** :

- Infrastructure 100% gratuite
- Backend toujours actif (pas de sommeil)
- RAM suffisante pour tous les modÃ¨les IA
- DÃ©ploiement automatisÃ©

### Phase 3 (Scale) :

- Microservices (service par modÃ¨le IA)
- Queue de traitement (Celery/RabbitMQ)
- Load balancing
- CDN pour les images

```

```
